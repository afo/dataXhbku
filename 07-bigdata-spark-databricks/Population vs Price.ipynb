{"cells":[{"cell_type":"markdown","source":["# Linear Regression: Population vs. Median Home Prices\n#### *Linear Regression with Single Variable*"],"metadata":{}},{"cell_type":"markdown","source":["*Note, this notebook requires Spark 2.0+* , check done below."],"metadata":{}},{"cell_type":"code","source":["%scala if (org.apache.spark.BuildInfo.sparkBranch < \"2.0\") sys.error(\"Attach this notebook to a cluster running Spark 2.0+\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Load and parse the data"],"metadata":{}},{"cell_type":"code","source":["# Use the Spark CSV datasource with options specifying:\n#  - First line of file is a header\n#  - Automatically infer the schema of the data\n#  - Note that we're using `spark` instead of `sqlContext` now.\ndata = spark.read.format(\"com.databricks.spark.csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"/databricks-datasets/samples/population-vs-price/data_geo.csv\")\ndata.cache()  # Cache data for faster reuse\ndata.count()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["display(data)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["data.printSchema()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["data = data.dropna()  # drop rows with missing values\ndata.count()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# This will let us access the table from sqlContext\ndata.createOrReplaceTempView(\"data_geo\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%sql select City, `State Code`, `2014 Population estimate`/1000 as `2014 Pop estimate`, `2015 median sales price` from data_geo"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["# Plot and group by state"],"metadata":{}},{"cell_type":"code","source":["%sql select `State Code`, AVG(`2015 median sales price`) from data_geo GROUP BY `State Code`"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Limit data to Population vs. Price\n(for our ML example)\n\nWe also use VectorAssembler to put this together"],"metadata":{}},{"cell_type":"code","source":["# Create DataFrame with just the data we want to run linear regression\ndf = spark.sql(\"select `2014 Population estimate`, `2015 median sales price` as label from data_geo\")\ndisplay(df)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(\n    inputCols=[\"2014 Population estimate\"],\n    outputCol=\"features\")\noutput = assembler.transform(df)\ndisplay(output.select(\"features\", \"label\"))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## Linear Regression\n\n**Goal**\n* Predict y = 2015 Median Housing Price\n* Using feature x = 2014 Population Estimate\n\n**References**\n* [MLlib LinearRegression user guide](http://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression)\n* [PySpark LinearRegression API](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression)"],"metadata":{}},{"cell_type":"code","source":["# Import LinearRegression class\nfrom pyspark.ml.regression import LinearRegression\n\n# Define LinearRegression algorithm\nlr = LinearRegression()\n\n# Fit 2 models, using different regularization parameters\nmodelA = lr.fit(output, {lr.regParam:0.0})\nmodelB = lr.fit(output, {lr.regParam:100.0})"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["print \">>>> ModelA intercept: %r, coefficient: %r\" % (modelA.intercept, modelA.coefficients[0])"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["print \">>>> ModelB intercept: %r, coefficient: %r\" % (modelB.intercept, modelB.coefficients[0])"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["## Make predictions\n\nCalling `transform()` on data adds a new column of predictions."],"metadata":{}},{"cell_type":"code","source":["# Make predictions\npredictionsA = modelA.transform(output)\ndisplay(predictionsA)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["## Evaluate the Model\n#### Predicted vs. True label"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(metricName=\"rmse\")\nRMSE = evaluator.evaluate(predictionsA)\nprint(\"ModelA: Root Mean Squared Error = \" + str(RMSE))"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["predictionsB = modelB.transform(output)\nRMSE = evaluator.evaluate(predictionsB)\nprint(\"ModelB: Root Mean Squared Error = \" + str(RMSE))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["# Linear Regression Plots"],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nfrom pandas import *\nfrom ggplot import *\n\npop = output.rdd.map(lambda p: (p.features[0])).collect()\nprice = output.rdd.map(lambda p: (p.label)).collect()\npredA = predictionsA.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\npredB = predictionsB.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\n\npydf = DataFrame({'pop':pop,'price':price,'predA':predA, 'predB':predB})"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["## View the Python Pandas DataFrame (pydf)"],"metadata":{}},{"cell_type":"code","source":["pydf"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["## ggplot figure\nNow that the Python Pandas DataFrame (pydf), use ggplot and display the scatterplot and the two regression models"],"metadata":{}},{"cell_type":"code","source":["p = ggplot(pydf, aes('pop','price')) + \\\n    geom_point(color='blue') + \\\n    geom_line(pydf, aes('pop','predA'), color='red') + \\\n    geom_line(pydf, aes('pop','predB'), color='green') + \\\n    scale_x_log10() + scale_y_log10()\ndisplay(p)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":31}],"metadata":{"name":"Pop. vs. Price LR 2.0","notebookId":3486959726874191},"nbformat":4,"nbformat_minor":0}
